{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate_policy, evaluate_policy\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from core.evaluate import interpolate_policy, evaluate_policy\n",
    "from agents.sac import SACAgent\n",
    "from agents.ddpg import DDPGAgent\n",
    "from agents.networks import ActorSAC, ActorDDPG\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths and configurations\n",
    "model_dir = \"model_weights/check_run (old, perhaps too short or too long)\"\n",
    "env_names = [\"Hopper-v5\", \"InvertedDoublePendulum-v5\"]\n",
    "algos = {\"SAC\": SACAgent, \"DDPG\": DDPGAgent}\n",
    "seeds = [0, 1, 2]\n",
    "alphas = [i * 0.05 for i in range(21)]  # 0.0 to 1.0 in steps of 0.05\n",
    "\n",
    "# Iterate over environments and algorithms\n",
    "for env_name in env_names:\n",
    "    env = gym.make(env_name)\n",
    "    for algo_name, agent_class in algos.items():\n",
    "        print(f\"\\n=== Interpolating for {algo_name} on {env_name} ===\")\n",
    "        \n",
    "        # Load models for different seeds\n",
    "        models = []\n",
    "        for seed in seeds:\n",
    "            model_path = os.path.join(model_dir, f\"{algo_name}Agent_{env_name}_seed{seed}.pt\")\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "            if algo_name == \"SAC\":\n",
    "                actor = ActorSAC(env.observation_space.shape[0], env.action_space.shape[0])\n",
    "            else:  # DDPG\n",
    "                actor = ActorDDPG(env.observation_space.shape[0], env.action_space.shape[0])\n",
    "            actor.load_state_dict(checkpoint['actor'])\n",
    "            models.append(actor)\n",
    "\n",
    "        # Evaluate each seed ~10 times and print average return\n",
    "        \n",
    "        for seed, model in enumerate(models):\n",
    "            avg_return = evaluate_policy(model, env, episodes=10)\n",
    "            print(f\"Seed {seed}: Average Return = {avg_return:.2f}\")\n",
    "\n",
    "        # Interpolate between models and evaluate\n",
    "        for i in range(len(models)):\n",
    "            for j in range(i + 1, len(models)):\n",
    "                print(f\"Interpolating between Seed {i} and Seed {j}\")\n",
    "                interpolation_results = []\n",
    "                for alpha in alphas:\n",
    "                    interpolated_actor = interpolate_policy(models[i], models[j], alpha)\n",
    "                    avg_return = evaluate_policy(interpolated_actor, env, episodes=5)\n",
    "                    interpolation_results.append((alpha, avg_return))\n",
    "                    # print(f\"Alpha {alpha:.2f}: Average Return = {avg_return:.2f}\")\n",
    "\n",
    "                # Graph the interpolation results\n",
    "                alphas, returns = zip(*interpolation_results)\n",
    "                plt.figure()\n",
    "                plt.plot(alphas, returns, marker='o', label=f\"Seed {i} â†” Seed {j}\")\n",
    "                plt.title(f\"Interpolation Results ({algo_name} on {env_name})\")\n",
    "                plt.xlabel(\"Alpha\")\n",
    "                plt.ylabel(\"Average Return\")\n",
    "                plt.legend()\n",
    "                plt.show()  # Display the plot instead of saving it\n",
    "\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
